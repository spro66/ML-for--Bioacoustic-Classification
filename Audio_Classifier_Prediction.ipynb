{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Audio Classifier Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMifDPYMpIgGaErIR6vmme7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "M58GvJsS-sZO"
      },
      "source": [
        "\n",
        "\n",
        "# Import required packages\n",
        "from __future__ import print_function, division\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.io import wavfile\n",
        "import pydub\n",
        "from pydub import AudioSegment\n",
        "import librosa\n",
        "import imageio\n",
        "import math\n",
        "import imageio\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "\n",
        "# Set the path that has your audio sample and teh .txt file from the detector\n",
        "data = 'PATH'\n",
        "\n",
        "# Reading file with start and end time \n",
        "input_file = pd.read_csv(data +'/'+ 'ARU18_20120410_090000.txt', encoding='utf-16',delimiter='\\t')#Location of the file with Begin and End time Information\n",
        "#print(input_file)\n",
        "\n",
        "\n",
        "\n",
        "# Selecting only the colmns of interest i.e. Start Time and End Time\n",
        "input_file_select = input_file.iloc[:,[2,3]]\n",
        "#print(input_file_select)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Splitting audio snippets on the basis of Begin and End Time. The code is creating snippets of 2 sec length with 1 sec overlap\n",
        "\n",
        "newAudio = AudioSegment.from_wav(data+'/'+'ARU18_20120410_090000.wav') #Location of the main Audio file\n",
        "\n",
        "# while input_file_select.iloc[len(input_file_select)-1,1] < duration_file:\n",
        "    \n",
        "for i in range(0, len(input_file_select)):\n",
        "  \n",
        "  t1 = input_file_select.iloc[i,0] * 1000\n",
        "  t2 = input_file_select.iloc[i,1] * 1000\n",
        "  leng_audio = t2 - t1\n",
        "  for j in range(0,math.ceil(leng_audio/2)):\n",
        "    if (t1+1000) <= t2:\n",
        "      finalAudio = newAudio[t1:t1+2000]\n",
        "      t1 = t1+1000\n",
        "      finalAudio.export(data+'/'+'samples'+'/'+'_'+str(i)+'_'+str(j)+'spec.wav', format='wav') #Exports to a wav file in the current path.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Generating Spectrograms from the 2 sec segmented snippets of the audio files\n",
        "  \n",
        "  # THIS IS THE PATH WHERE THE 2SEC SNIPPETS OF AUDIOFILES GENERATED FROM THE PREVIOUS STEP - LETS CALL ITS PATH_1\n",
        "path = Path('PATH_1').glob('**/*.wav')#Location of the path of the .wav files\n",
        "wavs = [str(wavf) for wavf in path if wavf.is_file()]\n",
        "wavs.sort()\n",
        "\n",
        "number_of_files=len(wavs)\n",
        "\n",
        "spk_ID = [wavs[i].split('/')[-1][:-4].lower() for i in range(number_of_files)]\n",
        "\n",
        "for i in range(number_of_files):\n",
        "    y, sr = librosa.load(wavs[i], sr=None)\n",
        "    \n",
        "    p =librosa.stft(y)\n",
        "    S = librosa.feature.melspectrogram(y, sr=44100, n_fft=2048, hop_length=512, n_mels=256)\n",
        "    log_S = librosa.amplitude_to_db(S)\n",
        "    mean = log_S.mean()\n",
        "    std = log_S.std()\n",
        "    S_norm = (log_S - mean) / (std + 1e-6)\n",
        "    S_min, S_max = S_norm.min(), S_norm.max()\n",
        "    S_scaled = 255 * (S_norm - S_min) / (S_max - S_min)\n",
        "    S_scaled = S_scaled.astype(np.uint8)\n",
        "      \n",
        "\n",
        "    #Storing the spectrograms of the 2 sec audio snippets at the same location as that of the audio snippets\n",
        "    save_path = 'PATH_1'\n",
        "    # # # plt.savefig(str(save_path)+\"{}.png\".format(spk_ID[i]))\n",
        "    # # np.save(str(save_path)+\"{}.npy\".format(spk_ID[i]),log_S)\n",
        "    imageio.imwrite(str(save_path)+\"{}.png\".format(spk_ID[i]),S_scaled[::-1])\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "# Load the saved model to make new predictions\n",
        "\n",
        "\n",
        "model_ft = torch.load('MODEL_LOCATION/final_resnet18_model_with_others_class.pt')\n",
        "model_ft.eval()\n",
        "\n",
        "\n",
        "trans = transforms.Compose([\n",
        "    # transforms.RandomHorizontalFlip(),\n",
        "    # transforms.Resize(32),\n",
        "    # transforms.CenterCrop(32),\n",
        "    \n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5]),\n",
        "    ])\n",
        "\n",
        "\n",
        "\n",
        "# Load images on which predictions to be made\n",
        "\n",
        "\n",
        "image_datasets_test = datasets.ImageFolder('PATH TO THE LEVEL UP OF SPECTROGRAM FOLDER(e.g. if images are at ./abc/def/ then just mention ./abc/',trans)\n",
        "                  \n",
        "dataloaders_test = torch.utils.data.DataLoader(image_datasets_test, batch_size=1, shuffle=False)\n",
        "\n",
        "f = open(\"PATH FOR FINAL OUTPUT .TXT FILE/final_prediction_4classes_1.txt\", \"w+\")\n",
        "with torch.no_grad():\n",
        "  for i, (image, labels) in enumerate(dataloaders_test):\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    image = image.to(device)\n",
        "    #labels = labels.to(device)\n",
        "    input = image.view(1, 3, 224, 224)\n",
        "    outputs = model_ft(input)\n",
        "    preds = int(torch.argmax(outputs, dim=1).cpu().numpy())\n",
        "    if (preds ==0):\n",
        "      preds = 'others'\n",
        "    if (preds ==1):\n",
        "      preds = 'PantHoot'\n",
        "    if (preds ==2):\n",
        "      preds = 'Drumming'\n",
        "    if (preds ==3):\n",
        "      preds = 'scream'\n",
        "      \n",
        "    # Uncomment the below section in order to compare the prediction with the ground truth\n",
        "    #if (labels ==0):\n",
        "     # labels = 'others'\n",
        "    #if (labels ==1):\n",
        "     # labels = 'ph'\n",
        "    #if (labels ==2):\n",
        "     # labels ='phtb'\n",
        "    #if (labels ==3):\n",
        "     # labels ='sm'\n",
        "    sample_fname, _ = dataloaders_test.dataset.samples[i]\n",
        "    #print(sample_fname+ \"Prediction :\" + preds + \" \" + \"Actual :\" + str(labels))\n",
        "    #print(sample_fname +\"\\tPred: \"+preds)\n",
        "    f.write(\"{}, \\t{}\\n\".format(sample_fname, preds))\n",
        "      \n",
        "f.close()\n",
        "      \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}